{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all neccesary libraries\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from datetime import timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data \n",
    "def cleanData(df,substance):\n",
    "    df = df.drop(columns=['historianTagnummer'])\n",
    "    df.rename(columns={'hstWaarde': substance + 'Value'}, inplace=True)\n",
    "    df[substance + 'Value'] = df[substance + 'Value'].astype(float)\n",
    "    df = df.drop(columns=['datumBeginMeting'])\n",
    "    df['datumEindeMeting'] = pd.to_datetime(df['datumEindeMeting'])\n",
    "    df.rename(columns={'datumEindeMeting': 'measurementDate'}, inplace=True)\n",
    "    df.to_parquet('../../data/cleanedData/'+ substance +'.parquet', index=False)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day light savings\n",
    "def shiftDates(df, name):\n",
    "    duplicates = df[df.duplicated(subset='measurementDate', keep=False)].index.tolist()\n",
    "    marchDate = df.loc[df['measurementDate'] == '2021-03-28 03:00:00']\n",
    "    startTime = marchDate.index.values[0]\n",
    "    endTime = duplicates[-1]\n",
    "\n",
    "    for i in range(startTime, endTime + 1):\n",
    "        if i < (endTime - len(duplicates)):\n",
    "            df.loc[i, 'measurementDate'] -= timedelta(hours=1)\n",
    "        elif not ((i % 2) == 0):\n",
    "            df.loc[i, 'measurementDate'] -= timedelta(hours=1)\n",
    "    \n",
    "    df = df.sort_values(by='measurementDate')\n",
    "    df.to_parquet('../../data/shiftedDates/'+ name +'.parquet', index=False)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine oxygen in both tanks \n",
    "def calculateOxygen(oxygenA, oxygenB):\n",
    "    if pd.isna(oxygenA):\n",
    "        oxygenA['oxygenAValue'].fillna(0)\n",
    "    elif pd.isna(oxygenB):\n",
    "        oxygenB['oxygenBValue'].fillna(0)\n",
    "    return (oxygenA + oxygenB)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load precipitaion and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "precepitation = pd.read_csv('../../data/precipitation.csv')\n",
    "precepitation.rename(columns={'time':'measurementDate','precipitation (mm)':'precipitation'},inplace=True)\n",
    "precepitation.drop(columns=['rain (mm)'],inplace=True)\n",
    "precepitation['measurementDate'] = pd.to_datetime(precepitation['measurementDate'])\n",
    "precepitation.to_parquet('../../data/shiftedDates/precipitation.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all files that need to be cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [\n",
    "    ('../../data/Ammonium_measurements.parquet', 'ammonium'),\n",
    "    ('../../data/Nitrate_measurements.parquet', 'nitrate'),\n",
    "    ('../../data/Oxygen_A.parquet', 'oxygenA'),\n",
    "    ('../../data/Oxygen_B.parquet', 'oxygenB'),\n",
    "    ('../../data/Phosphate_measurements.parquet', 'phosphate')\n",
    "]\n",
    "\n",
    "for file_path, var_name in data_files:\n",
    "    df = pd.read_parquet(file_path)\n",
    "    cleanData(df, var_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOad all files that need dayling saving shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = [\n",
    "    ('../../data/cleanedData/ammonium.parquet', 'cleanedAmmonium'),\n",
    "    ('../../data/cleanedData/nitrate.parquet', 'cleanedNitrate'),\n",
    "    ('../../data/cleanedData/oxygenA.parquet', 'cleanedOxygenA'),\n",
    "    ('../../data/cleanedData/oxygenB.parquet', 'cleanedOxygenB'),\n",
    "]\n",
    "\n",
    "for path_file, name in cleaned_data:\n",
    "    df = pd.read_parquet(path_file)\n",
    "    shiftDates(df, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge oxgenA and B datesets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygenA = pd.read_parquet('../../data/shiftedDates/cleanedOxygenA.parquet')\n",
    "oxygenB = pd.read_parquet('../../data/shiftedDates/cleanedOxygenB.parquet')\n",
    "\n",
    "oxygenAB = pd.merge(oxygenA, oxygenB, how=\"right\")\n",
    "oxygenAB['oxygenAValue'] = oxygenAB['oxygenAValue'].fillna(0)\n",
    "oxygenAB['oxygenBValue'] = oxygenAB['oxygenBValue'].fillna(0)\n",
    "oxygenAB[\"oxygenValue\"] = oxygenAB.apply(lambda col: calculateOxygen(col[\"oxygenAValue\"], col[\"oxygenBValue\"]), axis=1)\n",
    "oxygenAB.drop([\"oxygenAValue\", \"oxygenBValue\"], axis=1, inplace=True)\n",
    "oxygenAB.to_parquet('../../data/shiftedDates/oxygenAB.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning total influent waterflow dataset and prepare it for shifting as it requires special care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_csv('../../data/Total_influent_flow_WWTP_Ede_2021_minute_data.csv', sep=';')\n",
    "total['DateTime'] = pd.to_datetime(total['DateTime'], format='%d-%m-%Y %H:%M')\n",
    "total.drop(columns=['wwResolution'],inplace=True)\n",
    "total.rename(columns={'EDE_09902MTW_K100.MTW':'waterFlowPerMinute','DateTime':'measurementDate'}, inplace=True)\n",
    "\n",
    "total['waterFlowPerMinute'] = total['waterFlowPerMinute'].str.replace(',','.').replace('(null)', np.nan)\n",
    "total['waterFlowPerMinute'] = total['waterFlowPerMinute'].astype('float')\n",
    "total = total.sort_values(by='measurementDate')\n",
    "total = total.reset_index(drop=True)\n",
    "shiftDates(total,'cleanedTotal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned total influent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_parquet('../../data/shiftedDates/cleanedTotal.parquet')\n",
    "total = total.drop(index=436437)\n",
    "total.to_parquet('../../data/shiftedDates/cleanedTotal.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all files that need to be merged, merge them and save final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "              '../../data/shiftedDates/oxygenAB.parquet',\n",
    "              '../../data/shiftedDates/cleanedNitrate.parquet',\n",
    "              '../../data/cleanedData/phosphate.parquet',\n",
    "              '../../data/shiftedDates/cleanedAmmonium.parquet',\n",
    "              '../../data/shiftedDates/cleanedTotal.parquet',\n",
    "              '../../data/shiftedDates/precipitation.parquet'\n",
    "              ]\n",
    "\n",
    "dfs = [pd.read_parquet(path) for path in file_paths]\n",
    "merged = reduce(lambda left, right: pd.merge(left, right, how='outer', on='measurementDate'), dfs)\n",
    "merged.to_parquet('../../data/cleanedData/allDataClient.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode phosphate with obvious outlier, imput precipitaion data, save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../data/cleanedData/allDataClient.parquet')\n",
    "df['phosphateValue'] = df['phosphateValue'].map(lambda phosphate: -999 if pd.isnull(phosphate) else phosphate)\n",
    "precepitationIndex=0\n",
    "for row in df['precipitation']:\n",
    "    if not pd.isnull(row):\n",
    "        valuePerMinute = row/60\n",
    "        if precepitationIndex < 60:\n",
    "            df['precipitation'][:precepitationIndex] = valuePerMinute\n",
    "        else:\n",
    "            df['precipitation'][precepitationIndex-60:precepitationIndex] = valuePerMinute\n",
    "    precepitationIndex+=1\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "df.to_parquet('../../data/cleanedData/allDataClient.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert units of mesurement\n",
    "df['waterFlowPerMinute'] = df['waterFlowPerMinute'].apply(lambda row: row *1000) \n",
    "df.to_parquet('../../data/cleanedData/allDataClient.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info about the final training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
