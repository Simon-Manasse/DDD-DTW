{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data mining goal\n",
    "We aim to investigate the effect of chemicals (phosphate, ammonium, nitrate) together with precipitation on the oxygen level by means of predicting the oxygen in the influent water before the water is treated and drained into the environment. \n",
    "\n",
    "### Model choice\n",
    "\n",
    "Based on observation of data assumption we have decided to use Random Forest Regression. Main reasons behind the choice of this model are its properties such as: flexibility to outliers, proneness to overfitting, handling of non-linear and skewed data. These characteristics align nicely with our data which makes this model a suitable choice for achieving our data mining goal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score,mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Function that will encode time as a trigonometric function (sin, cos, etc.)\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame with a datetime index.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with added time-based and cyclic features. \n",
    "    \n",
    "    TODO: added error handling and improper use of provided dataset\n",
    "\t\"\"\"\n",
    "    df['minute'] = df.index.minute\n",
    "    df['hour'] = df.index.hour\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    \n",
    "    # Sine and cosine transformations for cyclic features\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
    "    \n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    \n",
    "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "    \n",
    "    df['quarter_sin'] = np.sin(2 * np.pi * df['quarter'] / 4)\n",
    "    df['quarter_cos'] = np.cos(2 * np.pi * df['quarter'] / 4)\n",
    "    \n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are dealing with time series data, we have to take past values into account due to autocorrelation. This means that the past values of features will be supplied as features to the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(df):\n",
    "    target_map = df['oxygenValue'].to_dict()\n",
    "    df['lag_1']=(df.index - pd.Timedelta('1 day')).map(target_map)\n",
    "    df['lag_2']=(df.index - pd.Timedelta('2 day')).map(target_map)\n",
    "    df['lag_3']=(df.index - pd.Timedelta('3 day')).map(target_map)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are loading the merged data set which contains all of the relevant features and target values. All values are **cleaned**.\n",
    "\n",
    "**Target**: oxygenValue\n",
    "\n",
    "**Features**: nitrateValue, phosphateValue, waterFlowPerMinute, precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/cleanedData/allData.parquet') #alternatively you can supply path as 'allData.parquet'\n",
    "df.set_index('measurementDate', inplace=True) \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specila case of k-fold validation to account for the time series data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=8, test_size=60*24*30, gap=60*24)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the k-fold for better interpretation and understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = list(tss.split(X_train_data))[::-1]\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(splits):\n",
    "    train = df.iloc[train_idx]\n",
    "    test = df.iloc[test_idx]\n",
    "    \n",
    "    plt.plot(train.index, [7 - i] * len(train), label=f'Train Fold {5 - i}', color='blue', linewidth=2)\n",
    "    plt.plot(test.index, [7 - i] * len(test), label=f'Test Fold {5 - i}', color='orange', linewidth=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data set into the train and test set which is sunsequently visualized using target values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df.index<'2021-10-01']\n",
    "test = df.loc[df.index>='2021-10-01']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "plt.plot(train.index,train['oxygenValue'])\n",
    "plt.plot(test.index,test['oxygenValue'])\n",
    "ax.axvline(pd.to_datetime('2021-10-01'),color='black', ls='--')\n",
    "plt.title(\"Distribution of train and test sets\")\n",
    "plt.legend(['Training Set','Test Set'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features and target to the appropriate variables according to our data mining goal. In addition to the chemical values, the features contain lag values to account for autocorrelation and various time measurements expressed by trigonometric functions to account for the seasonality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['nitrateValue', 'phosphateValue', 'ammoniumValue',\n",
    "            'waterFlowPerMinute', 'precipitation', 'minute_sin', 'minute_cos',\n",
    "            'hour_sin', 'hour_cos', 'dayofweek_sin', 'dayofweek_cos',\n",
    "            'quarter_sin', 'quarter_cos', 'month_sin', 'month_cos',\n",
    "            'lag_1', 'lag_2', 'lag_3']\n",
    "TARGET = 'oxygenValue'\n",
    "\n",
    "df = create_features(df)\n",
    "df= add_lags(df)\n",
    "train = df.loc[df.index<'2021-10-01']\n",
    "test = df.loc[df.index>='2021-10-01']\n",
    "X_train_data, y_train_data = train[FEATURES],train[FEATURES]\n",
    "X_test_data, y_test_data = test[FEATURES],test[FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have scalled our featrues to range from 0 to 1 as we have discovered by experimenting that scaling our features improves prefomance of the model by 0.01 mg/L in RMSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "FEATURES_TO_SCALE = ['nitrateValue', 'phosphateValue', 'ammoniumValue',\n",
    "            'waterFlowPerMinute','lag_1', 'lag_2', 'lag_3']\n",
    "X_train_data[FEATURES_TO_SCALE] = scaler.fit_transform(X_train_data[FEATURES_TO_SCALE]).copy()\n",
    "X_test_data[FEATURES_TO_SCALE] = scaler.transform(X_test_data[FEATURES_TO_SCALE]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "preds =[]\n",
    "scores =[]\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "paramsRF = {\n",
    "    \"bootstrap\": True,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"criterion\": \"squared_error\",\n",
    "    \"max_depth\": 10,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"max_samples\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 6,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"n_estimators\": 200,\n",
    "    \"n_jobs\": -1,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": None,\n",
    "    \"verbose\": 0,\n",
    "    \"warm_start\": False\n",
    "}\n",
    "\n",
    "rfr = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Modeling Using Random Forest Regression Algorithm\n",
    "\n",
    "Hyperparameters Stored in Separate Dictionary for Better Manipulation\n",
    "\n",
    "We've experimented with hyperparameters but haven't achieved optimal tuning.  We're considering using grid search to find the best ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for train_idx, val_idx in tss.split(X_train_data):\n",
    "    train = df.iloc[train_idx].copy()\n",
    "    test = df.iloc[val_idx].copy()\n",
    "\n",
    "    train = create_features(train)\n",
    "    test = create_features(test)\n",
    "    \n",
    "    X_train, y_train = train[FEATURES], train[TARGET]\n",
    "    X_test, y_test = test[FEATURES], test[TARGET]\n",
    "    y_train.dropna()\n",
    "\n",
    "    reg = RandomForestRegressor(**paramsRF)\n",
    "    rfr =  reg.fit(X_train, y_train)\n",
    "    fold += 1\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    preds.append(y_pred)\n",
    "    score = root_mean_squared_error(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mae_scores.append(mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature importance graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(data=reg.feature_importances_,\n",
    "             index=reg.feature_names_in_,\n",
    "             columns=[\"importance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.sort_values('importance').plot(kind='barh', title=\"Feature importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Score across folds: {np.mean(scores):0.4f}')\n",
    "print(f'Fold scores: {scores}')\n",
    "print(f'Mean Absolute Error: {np.mean(mae_scores):0.4f}')\n",
    "print(f'Mean Absolute Errors per fold: {mae_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER_PARAMETERS_DF: pd.DataFrame\n",
    "\n",
    "try:\n",
    "   HYPER_PARAMETERS_DF =  pd.read_csv('hyperParameters.csv')\n",
    "except:\n",
    "    HYPER_PARAMETERS_DF = pd.DataFrame(columns=[\n",
    "        \"bootstrap\", \"ccp_alpha\", \"criterion\", \"max_depth\", \n",
    "        \"max_features\", \"max_leaf_nodes\", \"max_samples\", \n",
    "        \"min_impurity_decrease\", \"min_samples_leaf\", \"min_samples_split\",\n",
    "        \"min_weight_fraction_leaf\", \"n_estimators\", \"n_jobs\", \"oob_score\", \n",
    "        \"random_state\", \"verbose\", \"warm_start\", \"MAE\", \"RMSE\"\n",
    "    ])\n",
    "\n",
    "new_row = pd.DataFrame([paramsRF])\n",
    "new_row['MAE'] = np.mean(mae_scores)\n",
    "new_row['RMSE'] = np.mean(scores)\n",
    "HYPER_PARAMETERS_DF = pd.concat([HYPER_PARAMETERS_DF, new_row], ignore_index=True)\n",
    "\n",
    "HYPER_PARAMETERS_DF.to_csv('hyperParameters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_data['prediction'] = reg.predict(X_test_data)\n",
    "df= df.merge(y_test_data[['prediction']],how='left',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[['oxygenValue']].plot(figsize=(20,10))\n",
    "df['prediction'].plot(ax=ax,style='.')\n",
    "plt.legend()\n",
    "ax.set_title('Raw data and predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = df.loc[(df.index > '2021-11-05') & (df.index < '2021-11-06')]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Oxygen values over a day\")\n",
    "plt.plot(day.index,day['oxygenValue'])\n",
    "plt.plot(day.index,day['prediction'])\n",
    "plt.xlabel('Hours of the day')\n",
    "plt.ylabel('Oxygen values')\n",
    "plt.legend([\"Oxygen\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
